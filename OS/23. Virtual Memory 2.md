> 본 글은 이화여대 반효경 교수님의 [운영체제 강의(2014)](http://www.kocw.net/home/search/kemView.do?kemId=1046323) 내용에 대해 학습하고 정리한 내용입니다.


# 23. Virtual Memory 2

## 0. 다양한 캐싱 환경 

캐싱이란 한정된 빠른 공간(캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청 시 캐쉬로부터 직접 서비스하는 방식이다. 

캐싱은 paging system 외에도 cache memory(cpu가 메인 메모리에 접근하기 전에 미리 살펴보는 곳), buffer caching, web caching등 다양한 분야에서 사용된다. 

> 앞서 봤던 LRU, LFU 알고리즘의 경우 paging system에서 사용되기 어렵다고 한다. 
> 이미 페이지가 물리적인 메모리에 올라와있는 경우에는, 프로세스가 cpu를 가지기 때문에 OS는 참조 시각등의 정보를 얻지 못한다. 다만 page fault가 발생했을 때만 OS에게 cpu가 넘어가서 관여할 수 있다. 

## 1. Clock Algorithm 

LRU 알고리즘을 근사시킨 알고리즘이다. Second change algorithm, NUR(Not Used Recently), NRU(Not Recently Used)등 여러 명칭으로 불리기도 한다. 

Clock algorithm은 reference bit이란 것을 사용해서 교체 대상 페이지를 선정한다. reference bit은 최근에 참조된 페이지인지 여부를 0,1로 나타낸다. 메모리에서 교체 대상 페이지를 찾기 위해 reference bit가 0인 것을 찾아야 한다. 포인터가 이동하는 중에 reference bit가 1인 것은 모두 0으로 변경하고 포인터를 이동해준다. reference bit가 0인 것을 찾으면 그 때 페이지를 교체하게 되는 것이다. 

만약 한 바퀴를 돌아왔는데도 0이면, 그 때에는 replace 당한다.

우선 물리적인 메모리에서 참조하게 되면 reference bit을 1로 변경하여 최근에 참조된 페이지라고 표시해준다. 

- reference bit = 1: 최근에 참조된 페이지
- modified bit = 1: 최근에 변경된 페이지

![](https://i.imgur.com/yVAsTNz.png)

reference bit이 1이면 0으로 바꾸고 다음 메모리를 확인한다. 그러다 0인 것을 마주하면 교체 대상 페이지가 되는 것이다. 

## 2. Page Frame의 Allocation

각 프로세스에 얼마만큼의 page frame을 할당할 것인가에 대한 문제이다. 

loop를 구성하는 페이지들은 한 번에 allocate되는 것이 유리하다. 최소한의 allocation이 없으면 매 loop마다 page fault가 발생하게 된다. 

한 프로그램이 메모리를 독차지하게 되면, 다른 프로그램이 메모리에 올라와 있지 못해 비효율적이게 된다. 즉 allocation은 하나의 프로그램에 어느 정도의 메모리 페이지를 나누어 주는 것을 보장하는 역할을 한다. 

- Allocation Scheme
    - Equal allocation: 모든 프로세스에 똑같은 개수 할당 
    - Proportional allocation: 프로세스 크기에 비례하여 할당
    - Priority allocation: 프로세스의 priority에 따라 다르게 할당

## 3. Global vs Local Replacement

어떤 프로그램이 메모리를 많이 필요로 하면, 그 때는 해당 프로그램의 메모리가 많이 올라와서 다른 프로그램의 페이지가 쫓겨날 수 있게 된다. 

이에 굳이 미리 할당하지 않고, 알아서 알고리즘에 의해 프로세스별로 메모리 할당량을 바뀌도록 하는 것이 global replacement이다.

- Global replacement
    - replace될 때, 다른 프로세스에 할당된 frame을 뺏을 수 있다.
    - process별 할당량을 조절하는 또 다른 방법이다
    - Working set, PFF 알고리즘 사용
- Local replacement
    - 자신에게 할당된 frame 내에서만 replacement한다.

## 4. Thrashing 

Thrashing이란, 프로그램에게 메모리가 너무 적게 할당되어서 page fault가 빈번하게 발생하는 경우를 의미한다. 

![](https://i.imgur.com/J904Wa3.png)

가로 축은 메모리에 올라와있는 프로그램의 개수이고, 세로축은 cpu 이용률이다. 

어느 지점부터는 cpu 이용률이 줄어드는데, 이 때가 thrashing이 발생한 지점이 된다. 

앞서 말한 것 처럼 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당받지 못했기 때문에 trashing이 발생한다. 이 때문에 page fault 빈도가 매우 높아지고, cpu 이용률도 낮아지게 된다. 

왜냐하면 cpu가 instruction을 실행하려고 하면 메모리에 매번 없어서 I/O를 해야하는데, 이러한 과정이 반복되기에 비효율적이게 되는 것이다. 

그런데 OS는 cpu 이용률을 보고, 이를 개선시키기 위해 MPD(Multiprogramming degree)를 높여야 한다고 판단한다. 하지만 그럴수록 프로세스 당 할당된 frame의 수는 더욱 감소되고, 프로세스는 page swap in/out하는 과정을 반복하기에 매우 바쁘게 된다. 이렇게 메모리에 올리고 내리고 하는 상황에서는 cpu가 놀기 때문에 점점 cpu 이용률은 계속 낮아지게 된다. 

이러한 상황을 막기 위해서는 MPD를 조절해야한다. 즉 동시에 올라가있는 프로그램의 수를 조절해서 프로세스의 메모리를 확보해줘야 한다. 

## 5. Working-Set Model

프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조하는 특징을 가지고 있다(= locality of reference) 집중적으로 참조되는 해당 page들의 집합을 locality set이라 한다. 이 알고리즘 내에서는 working set이라고 부르기도 하며, 빈번히 참조되야하는 집합들을 의미한다. 

즉, working set은 locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한 번에 메모리에 올라와 있어야 하는 page들의 집합을 말하는 것이다. 

만약 페이지가 5개가 필요한데, 3개만 줄 수 있는 경우 working set 모델에서는 프로세스의 working set의 모든 frame을 반납하고 swap out(suspend)된다. 다 보장해주지 못하면 아예 포기해버린다는 것이다.

이러한 방법을 통해 trashing을 방지하고, MPD를 조절해준다.

![](https://i.imgur.com/VktEKsr.png)

과거를 통해 working set을 추정하게 된다. 예를 들어 그림처럼 10의 시간만큼 해당하는 page들을 보면 {1,2,5,6,7}이 해당되는 것을 볼 수 있다. 이것이 바로 working set이 되며, working set 알고리즘은 5개의 페이지 프레임을 줄 수 있으면 {1,2,5,6,7}을 메모리에 올려둔다. 상황이 안된다면 swap out하게 되는 것이다. 

쭉 이동시키면 시점에 따라 working set의 개수가 다른 것을 볼 수 있다. 

다른 말로 이해해보면, 참조된 후 델타 시간 동안 해당 page를 메모리에 유지한 후 버린다고도 볼 수 있다. 

## 6. PFF(Page Fault Frequency) Scheme

![](https://i.imgur.com/i1A2DQV.png)

직접 page fault rate를 살펴보며 행동하는 방식이다.
기본적으로 page fault rate의 상한값/하한값을 두게 된다.

- page fault rate가 상한값을 넘으면 frame을 더 할당한다.
- page fault rate가 하한값 이하이면 할당 frame 수를 줄인다. 
  
비어있는 frame이 없다면(= 줄 수 있는 frame이 없다면) 일부 프로세스를 swap out시켜서 trashing을 방지하게 된다. 

## 7. Page Size의 결정 

Page size는 기본적으로 4kb로 사용하고 있다. 하지만 주소 체계가 32bit에서 64bit로 이동하거나, 메모리 크기도 점점 커지고 있기 때문에 page size가 너무 작은 경우, page 수가 늘어나게 된다! (분자는 커지는데 분모는 그대로인 상황)

Page size를 줄이게 되면 페이지 수가 늘어나기 때문에, 페이지 테이블 크기 또한 증가된다. 대신에 잘게 쪼개기 때문에 페이지 내부에서 사용이 안되는 부분이 생길 수 있는 문제는 개선될 수 있다. 즉 내부 조각이 감소할 수 있다는 것이다.

특히 필요한 정보만 메모리에 올라오기 때문에 메모리 이용이 효율적일 수 있다. 페이지가 큰 경우에 일부만 필요로 하더라도 page fault가 발생하면 큰 페이지를 전부 메모리에 올려야 한다. 즉 필요한 정보만 올라오지 않을 수 있다는 것이다. 

Disk transfer의 효율성은 페이지가 커질 수록 좋아진다. disk는 기본적으로 헤드가 이동하면서 특정 위치에가서 읽거나 써야 한다. 하지만 찾는 시간이 오래걸리기 때문에 한 번 이동해서 많은 양을 읽어오는게 효율적이다. 그런데 페이지 크기가 작으면 page fault가 발생할 때 마다, 헤드를 이동시키고 찾아오는 빈도가 높아져 비효율적일 수 있다는 것이다.

그래서 최근에는 큰 크기의 페이지를 주로 사용하는 추세라고 한다!
